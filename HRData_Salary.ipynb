{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education_Num</th>\n",
       "      <th>Martial_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Capital_Gain</th>\n",
       "      <th>Capital_Loss</th>\n",
       "      <th>Hours_per_week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Salary_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age          Workclass   Education  Education_Num       Martial_Status  \\\n",
       "0  39.0          State-gov   Bachelors             13        Never-married   \n",
       "1  50.0   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "         Occupation    Relationship    Race Gender  Capital_Gain  \\\n",
       "0      Adm-clerical   Not-in-family   White   Male          2174   \n",
       "1   Exec-managerial         Husband   White   Male             0   \n",
       "\n",
       "   Capital_Loss  Hours_per_week         Country Salary_Group  \n",
       "0             0            40.0   United-States        <=50K  \n",
       "1             0            13.0   United-States        <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('HR_data1.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data=data.select_dtypes(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_data.columns:\n",
    "    data[i]=data[i].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K', '<=50K.', '>50K.'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Salary_Group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Salary_Group']=data['Salary_Group'].replace({'<=50K':0,'<=50K.':0,'>50K.':1,'>50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.758918\n",
       "1    0.241082\n",
       "Name: Salary_Group, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Salary_Group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0.054754\n",
       "Workclass         0.056917\n",
       "Education         0.000000\n",
       "Education_Num     0.000000\n",
       "Martial_Status    0.000000\n",
       "Occupation        0.057136\n",
       "Relationship      0.000000\n",
       "Race              0.000000\n",
       "Gender            0.000000\n",
       "Capital_Gain      0.000000\n",
       "Capital_Loss      0.000000\n",
       "Hours_per_week    0.030087\n",
       "Country           0.017959\n",
       "Salary_Group      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data=data.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install missingpy\n",
    "#from missingpy import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "impu=KNNImputer()\n",
    "num_data_fill=impu.fit_transform(num_data)\n",
    "num_data_fill=pd.DataFrame(num_data_fill,columns=num_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Education_Num     0\n",
       "Capital_Gain      0\n",
       "Capital_Loss      0\n",
       "Hours_per_week    0\n",
       "Salary_Group      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_fill.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workclass         0.056917\n",
       "Education         0.000000\n",
       "Martial_Status    0.000000\n",
       "Occupation        0.057136\n",
       "Relationship      0.000000\n",
       "Race              0.000000\n",
       "Gender            0.000000\n",
       "Country           0.017959\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data=data.select_dtypes(exclude=np.number)\n",
    "cat_data.isnull().sum()/len(cat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private             0.738533\n",
      "Self-emp-not-inc    0.082588\n",
      "Local-gov           0.068306\n",
      "State-gov           0.042180\n",
      "Self-emp-inc        0.036287\n",
      "Federal-gov         0.031410\n",
      "Without-pay         0.000464\n",
      "Never-worked        0.000232\n",
      "Name: Workclass, dtype: float64\n",
      "United-States                 0.912213\n",
      "Mexico                        0.019849\n",
      "Philippines                   0.006189\n",
      "Germany                       0.004321\n",
      "Canada                        0.003903\n",
      "Puerto-Rico                   0.003680\n",
      "El-Salvador                   0.003178\n",
      "India                         0.003122\n",
      "Cuba                          0.002927\n",
      "England                       0.002704\n",
      "China                         0.002593\n",
      "South                         0.002565\n",
      "Jamaica                       0.002397\n",
      "Italy                         0.002286\n",
      "Dominican-Republic            0.002202\n",
      "Vietnam                       0.002091\n",
      "Japan                         0.001979\n",
      "Guatemala                     0.001924\n",
      "Columbia                      0.001896\n",
      "Poland                        0.001728\n",
      "Taiwan                        0.001533\n",
      "Iran                          0.001422\n",
      "Haiti                         0.001338\n",
      "Portugal                      0.001227\n",
      "Nicaragua                     0.001059\n",
      "Greece                        0.001004\n",
      "Peru                          0.000920\n",
      "France                        0.000864\n",
      "Ecuador                       0.000864\n",
      "Ireland                       0.000753\n",
      "Hong                          0.000669\n",
      "Trinadad&Tobago               0.000641\n",
      "Cambodia                      0.000613\n",
      "Thailand                      0.000558\n",
      "Laos                          0.000558\n",
      "Outlying-US(Guam-USVI-etc)    0.000474\n",
      "Yugoslavia                    0.000474\n",
      "Scotland                      0.000446\n",
      "Hungary                       0.000418\n",
      "Honduras                      0.000390\n",
      "Holand-Netherlands            0.000028\n",
      "Name: Country, dtype: float64\n",
      "Prof-specialty       0.134785\n",
      "Craft-repair         0.133420\n",
      "Exec-managerial      0.131707\n",
      "Adm-clerical         0.122358\n",
      "Sales                0.119744\n",
      "Other-service        0.106852\n",
      "Machine-op-inspct    0.064895\n",
      "Transport-moving     0.052003\n",
      "Handlers-cleaners    0.044774\n",
      "Farming-fishing      0.031707\n",
      "Tech-support         0.030865\n",
      "Protective-serv      0.021603\n",
      "Priv-house-serv      0.004994\n",
      "Armed-Forces         0.000290\n",
      "Name: Occupation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cat_data['Workclass'].value_counts(normalize=True))\n",
    "print(cat_data['Country'].value_counts(normalize=True))\n",
    "print(cat_data['Occupation'].value_counts(normalize=True))\n",
    "\n",
    "#If we dont know what to do with missing value in categorical variables, we may introduce a new level called as 'Missing'\n",
    "#ML will understand the level Missing\n",
    "#If there is any pattern in missing , using ML we can predict the values later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data['Occupation']=cat_data['Occupation'].fillna('Missing')\n",
    "cat_data['Country']=cat_data['Country'].fillna(cat_data['Country'].mode()[0])\n",
    "cat_data['Workclass']=cat_data['Workclass'].fillna(cat_data['Workclass'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workclass         0\n",
       "Education         0\n",
       "Martial_Status    0\n",
       "Occupation        0\n",
       "Relationship      0\n",
       "Race              0\n",
       "Gender            0\n",
       "Country           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.concat([num_data_fill,cat_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Num</th>\n",
       "      <th>Capital_Gain</th>\n",
       "      <th>Capital_Loss</th>\n",
       "      <th>Hours_per_week</th>\n",
       "      <th>Salary_Group</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education</th>\n",
       "      <th>Martial_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Education_Num  Capital_Gain  Capital_Loss  Hours_per_week  \\\n",
       "0  39.0           13.0        2174.0           0.0            40.0   \n",
       "1  50.0           13.0           0.0           0.0            13.0   \n",
       "\n",
       "   Salary_Group         Workclass  Education      Martial_Status  \\\n",
       "0           0.0         State-gov  Bachelors       Never-married   \n",
       "1           0.0  Self-emp-not-inc  Bachelors  Married-civ-spouse   \n",
       "\n",
       "        Occupation   Relationship   Race Gender        Country  \n",
       "0     Adm-clerical  Not-in-family  White   Male  United-States  \n",
       "1  Exec-managerial        Husband  White   Male  United-States  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_final['Salary_Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODING\n",
    "#when we dont know ordinal or nominal we consider that to be nominal. \n",
    "#nominal cant be considered ordinal but if ordinal is considered as nominal then not a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['Occupation']=data_final.groupby('Occupation')['Salary_Group'].transform('sum')\n",
    "\n",
    "#This one above is Target encoding - preffered to use when multiple levels in input column also when inp column not Ordinal\n",
    "#For each and every occupation level, it will tell how many people above 50K\n",
    "\n",
    "#If op was continuous - We can use Avg salary as level to represent the occupation\n",
    "\n",
    "#Encoding using Target column , then it will be helpful in understanding the OP. dont do with ip as it cause multicollinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['Occupation']=data_final['Occupation']/len(data_final)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['Country']=data_final.groupby('Country')['Salary_Group'].transform('sum')\n",
    "data_final['Country']=data_final['Country']/len(data_final)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['Workclass']=data_final.groupby('Workclass')['Salary_Group'].transform('sum')\n",
    "data_final['Workclass']=data_final['Workclass']/len(data_final)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['Martial_Status']=data_final.groupby('Martial_Status')['Salary_Group'].transform('sum')\n",
    "data_final['Martial_Status']=data_final['Martial_Status']/len(data_final)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['Relationship']=data_final.groupby('Relationship')['Salary_Group'].transform('sum')\n",
    "data_final['Relationship']=data_final['Relationship']/len(data_final)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=data_final.drop('Education',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.get_dummies(data_final,columns=['Gender','Race'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Num</th>\n",
       "      <th>Capital_Gain</th>\n",
       "      <th>Capital_Loss</th>\n",
       "      <th>Hours_per_week</th>\n",
       "      <th>Salary_Group</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Martial_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Race_Asian-Pac-Islander</th>\n",
       "      <th>Race_Black</th>\n",
       "      <th>Race_Other</th>\n",
       "      <th>Race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.067703</td>\n",
       "      <td>1.500260</td>\n",
       "      <td>1.555014</td>\n",
       "      <td>2.625455</td>\n",
       "      <td>22.473787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.217538</td>\n",
       "      <td>20.579298</td>\n",
       "      <td>5.970926</td>\n",
       "      <td>18.222137</td>\n",
       "      <td>22.473787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Education_Num  Capital_Gain  Capital_Loss  Hours_per_week  \\\n",
       "0  39.0           13.0        2174.0           0.0            40.0   \n",
       "1  50.0           13.0           0.0           0.0            13.0   \n",
       "\n",
       "   Salary_Group  Workclass  Martial_Status  Occupation  Relationship  \\\n",
       "0           0.0   1.067703        1.500260    1.555014      2.625455   \n",
       "1           0.0   2.217538       20.579298    5.970926     18.222137   \n",
       "\n",
       "     Country  Gender_Male  Race_Asian-Pac-Islander  Race_Black  Race_Other  \\\n",
       "0  22.473787            1                        0           0           0   \n",
       "1  22.473787            1                        0           0           0   \n",
       "\n",
       "   Race_White  \n",
       "0           1  \n",
       "1           1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "inp=data_final.drop('Salary_Group',axis=1)\n",
    "out=data_final['Salary_Group']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(inp,out,test_size=0.3,random_state=48)\n",
    "\n",
    "lm=LogisticRegression()\n",
    "lm.fit(xtrain,ytrain)\n",
    "ypred=lm.predict(xtest)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=data_final.drop('Salary_Group',axis=1)\n",
    "out=data_final['Salary_Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(inp,out,test_size=0.3,random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LogisticRegression()\n",
    "lm.fit(xtrain,ytrain)\n",
    "ypred=lm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.91      0.87      8276\n",
      "         1.0       0.62      0.45      0.52      2683\n",
      "\n",
      "    accuracy                           0.80     10959\n",
      "   macro avg       0.73      0.68      0.70     10959\n",
      "weighted avg       0.78      0.80      0.79     10959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))\n",
    "\n",
    "#one class performance is good while other class is not good? Reason could be Imbalance which we are dealing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    27721\n",
       "1.0     8806\n",
       "Name: Salary_Group, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['Salary_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss \n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0 = 20000\n",
    "count_class_1 = 14000\n",
    "pipe = make_pipeline(SMOTE(sampling_strategy={1: count_class_1})\n",
    "                    ,NearMiss(sampling_strategy={0: count_class_0}))\n",
    "inp_bal, out_bal = pipe.fit_resample(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(inp_bal,out_bal,test_size=0.3,random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LogisticRegression()\n",
    "lm.fit(xtrain,ytrain)\n",
    "ypred=lm.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.86      0.82      6016\n",
      "         1.0       0.77      0.66      0.71      4184\n",
      "\n",
      "    accuracy                           0.78     10200\n",
      "   macro avg       0.78      0.76      0.76     10200\n",
      "weighted avg       0.78      0.78      0.77     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))\n",
    "\n",
    "#Now we have improved performance of the Model and its some what good and eqal as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=lm.predict_proba(xtest)\n",
    "prob_1=prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The report for Th =  0.2\n",
      "[[2937 3079]\n",
      " [ 217 3967]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.49      0.64      6016\n",
      "         1.0       0.56      0.95      0.71      4184\n",
      "\n",
      "    accuracy                           0.68     10200\n",
      "   macro avg       0.75      0.72      0.67     10200\n",
      "weighted avg       0.78      0.68      0.67     10200\n",
      "\n",
      "The report for Th =  0.3\n",
      "[[3789 2227]\n",
      " [ 496 3688]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.63      0.74      6016\n",
      "         1.0       0.62      0.88      0.73      4184\n",
      "\n",
      "    accuracy                           0.73     10200\n",
      "   macro avg       0.75      0.76      0.73     10200\n",
      "weighted avg       0.78      0.73      0.73     10200\n",
      "\n",
      "The report for Th =  0.4\n",
      "[[4570 1446]\n",
      " [ 940 3244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.76      0.79      6016\n",
      "         1.0       0.69      0.78      0.73      4184\n",
      "\n",
      "    accuracy                           0.77     10200\n",
      "   macro avg       0.76      0.77      0.76     10200\n",
      "weighted avg       0.77      0.77      0.77     10200\n",
      "\n",
      "The report for Th =  0.5\n",
      "[[5199  817]\n",
      " [1443 2741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.86      0.82      6016\n",
      "         1.0       0.77      0.66      0.71      4184\n",
      "\n",
      "    accuracy                           0.78     10200\n",
      "   macro avg       0.78      0.76      0.76     10200\n",
      "weighted avg       0.78      0.78      0.77     10200\n",
      "\n",
      "The report for Th =  0.6\n",
      "[[5426  590]\n",
      " [1734 2450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.90      0.82      6016\n",
      "         1.0       0.81      0.59      0.68      4184\n",
      "\n",
      "    accuracy                           0.77     10200\n",
      "   macro avg       0.78      0.74      0.75     10200\n",
      "weighted avg       0.78      0.77      0.76     10200\n",
      "\n",
      "The report for Th =  0.8\n",
      "[[5925   91]\n",
      " [2687 1497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.98      0.81      6016\n",
      "         1.0       0.94      0.36      0.52      4184\n",
      "\n",
      "    accuracy                           0.73     10200\n",
      "   macro avg       0.82      0.67      0.66     10200\n",
      "weighted avg       0.79      0.73      0.69     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0.2,0.3,0.4,0.5,0.6,0.8]:\n",
    "    ypred1=np.zeros([len(ytest),1])\n",
    "    ypred1[prob_1>=i]=1\n",
    "    print(\"The report for Th = \",i)\n",
    "    print(confusion_matrix(ytest,ypred1))\n",
    "    print(classification_report(ytest,ypred1))\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Can Check youden index and Cost function and see if it improves even further"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we know base model performance for both imbalanced data, partially balanced data.\n",
    "Now we are applying other non linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(max_iter=3000)\n",
    "clf2= DecisionTreeClassifier(random_state=0)\n",
    "clf3=  RandomForestClassifier(random_state=0)\n",
    "clf4 = KNeighborsClassifier(n_neighbors=5) \n",
    "clf5= GaussianNB()\n",
    "clf6=XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=KFold(n_splits=5,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8150588235294117 0.007460705038914762\n",
      "DT 0.8103823529411762 0.0051870779150686675\n",
      "RF 0.8484411764705883 0.004393930940011614\n",
      "KNN 0.8220588235294117 0.006294315594189321\n",
      "GNB 0.7179117647058824 0.005766815962882327\n",
      "XGB 0.866235294117647 0.007039612039508859\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip([clf1,clf2,clf3,clf4,clf5,clf6],['LR','DT','RF','KNN','GNB','XGB']):\n",
    "    score = cross_val_score(i, inp_bal, out_bal, cv=kf, scoring='accuracy')\n",
    "    print(j,np.mean(score),np.std(score)/np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.9050251189850721 0.005278148167631491\n",
      "DT 0.8178492490366361 0.006175360624048297\n",
      "RF 0.9256036135862263 0.004013530266992375\n",
      "KNN 0.8935697517515357 0.0050579733209833505\n",
      "GNB 0.8847227353969661 0.006021800810313691\n",
      "XGB 0.9421009680981871 0.003580788659216921\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip([clf1,clf2,clf3,clf4,clf5,clf6],['LR','DT','RF','KNN','GNB','XGB']):\n",
    "    score = cross_val_score(i, inp_bal, out_bal, cv=kf, scoring='roc_auc')\n",
    "    print(j,np.mean(score),np.std(score)/np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.7633697315296748 0.010639370472498117\n",
      "DT 0.7668596781581595 0.007023331365043273\n",
      "RF 0.811642981685527 0.006399540701020579\n",
      "KNN 0.7838583418118559 0.009349513737719091\n",
      "GNB 0.4832593900595709 0.02666271856017359\n",
      "XGB 0.8329968547150838 0.00914188179098438\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip([clf1,clf2,clf3,clf4,clf5,clf6],['LR','DT','RF','KNN','GNB','XGB']):\n",
    "    score = cross_val_score(i, inp_bal, out_bal, cv=kf, scoring='f1')\n",
    "    print(j,np.mean(score),np.std(score)/np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8989198210608595 0.002384020401393769\n",
      "DT 0.7710718894676816 0.005401157241002866\n",
      "RF 0.9024231645997516 0.002573337980175636\n",
      "KNN 0.8836767586164547 0.003765416888283441\n",
      "GNB 0.8763021219557865 0.0024085509441939823\n",
      "XGB 0.9305554251294861 0.0027959411482692824\n"
     ]
    }
   ],
   "source": [
    "#Same one we are doing with imbalanced data below\n",
    "\n",
    "for i,j in zip([clf1,clf2,clf3,clf4,clf5,clf6],['LR','DT','RF','KNN','GNB','XGB']):\n",
    "    score = cross_val_score(i, inp, out, cv=kf, scoring='roc_auc')\n",
    "    print(j,np.mean(score),np.std(score)/np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier or Stacking - here we have done voting classifier\n",
    "#whatever algorithm is doing only include in the VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "estimator=[('lr',LogisticRegression(max_iter=3000)),('KNN',KNeighborsClassifier()),('rf',RandomForestClassifier()),('nb',GaussianNB()),\n",
    "          ('xb',XGBClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot1=VotingClassifier(estimators=estimator, voting='hard')\n",
    "vot2=VotingClassifier(estimators=estimator, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vot1 0.8031841879073202 0.008230372090854303\n",
      "vot2 0.7932049114831894 0.005881790278420995\n"
     ]
    }
   ],
   "source": [
    "score_vot1 = cross_val_score(vot1, inp_bal, out_bal, cv=kf, scoring='f1')\n",
    "score_vot2 = cross_val_score(vot2, inp_bal, out_bal, cv=kf, scoring='f1')\n",
    "print('vot1',np.mean(score_vot1),np.std(score_vot1)/np.mean(score_vot1))\n",
    "print('vot2',np.mean(score_vot2),np.std(score_vot2)/np.mean(score_vot2))\n",
    "\n",
    "#Not actually doing do as RF=81 got reduced to 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Whatever model is doing good pick those models and then tune it - Here RandomForrest and XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(xtrain,ytrain)\n",
    "ypred=rf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp=pd.DataFrame()\n",
    "feat_imp['Feature']=xtrain.columns\n",
    "feat_imp['Importance']=rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.203119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education_Num</td>\n",
       "      <td>0.136041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>0.134286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Martial_Status</td>\n",
       "      <td>0.132606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hours_per_week</td>\n",
       "      <td>0.101646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capital_Gain</td>\n",
       "      <td>0.095832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Relationship</td>\n",
       "      <td>0.079123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Workclass</td>\n",
       "      <td>0.041871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Capital_Loss</td>\n",
       "      <td>0.034694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Country</td>\n",
       "      <td>0.014746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gender_Male</td>\n",
       "      <td>0.010299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Race_White</td>\n",
       "      <td>0.006604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Race_Black</td>\n",
       "      <td>0.005398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Race_Asian-Pac-Islander</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Race_Other</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Importance\n",
       "0                       Age    0.203119\n",
       "1             Education_Num    0.136041\n",
       "7                Occupation    0.134286\n",
       "6            Martial_Status    0.132606\n",
       "4            Hours_per_week    0.101646\n",
       "2              Capital_Gain    0.095832\n",
       "8              Relationship    0.079123\n",
       "5                 Workclass    0.041871\n",
       "3              Capital_Loss    0.034694\n",
       "9                   Country    0.014746\n",
       "10              Gender_Male    0.010299\n",
       "14               Race_White    0.006604\n",
       "12               Race_Black    0.005398\n",
       "11  Race_Asian-Pac-Islander    0.002737\n",
       "13               Race_Other    0.000997"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values('Importance',ascending=False)\n",
    "\n",
    "#Age plays major factor in deciding the Salary(Target) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                        46.000000\n",
       "Education_Num               9.000000\n",
       "Capital_Gain                0.000000\n",
       "Capital_Loss                0.000000\n",
       "Hours_per_week             30.000000\n",
       "Workclass                  15.870452\n",
       "Martial_Status              1.420867\n",
       "Occupation                  0.865113\n",
       "Relationship                2.625455\n",
       "Country                    22.473787\n",
       "Gender_Male                 0.000000\n",
       "Race_Asian-Pac-Islander     0.000000\n",
       "Race_Black                  0.000000\n",
       "Race_Other                  0.000000\n",
       "Race_White                  1.000000\n",
       "Name: 18476, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " xtest.iloc[50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.        ,  9.        ,  0.        ,  0.        , 30.        ,\n",
       "        15.87045199,  1.42086676,  0.86511348,  2.62545514, 22.47378651,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obser = xtest.iloc[50,:].values.reshape(1,-1)\n",
    "obser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(rf,obser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.067, -0.067],\n",
       "        [ 0.037, -0.037],\n",
       "        [ 0.021, -0.021],\n",
       "        [ 0.006, -0.006],\n",
       "        [ 0.021, -0.021],\n",
       "        [ 0.006, -0.006],\n",
       "        [ 0.141, -0.141],\n",
       "        [ 0.017, -0.017],\n",
       "        [ 0.101, -0.101],\n",
       "        [ 0.   , -0.   ],\n",
       "        [-0.002,  0.002],\n",
       "        [ 0.   , -0.   ],\n",
       "        [-0.002,  0.002],\n",
       "        [-0.   ,  0.   ],\n",
       "        [-0.   ,  0.   ]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(contributions,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58732647, 0.41267353]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(contributions[0][:,0]) + bias[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sum(contributions[0][:,1]) + bias[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimator: 5\n",
      "Bias Error 0.20560777023726662\n",
      "Variance Error 0.004670226035631353\n",
      "n_estimator: 10\n",
      "Bias Error 0.20073133686288092\n",
      "Variance Error 0.006138235513966174\n",
      "n_estimator: 20\n",
      "Bias Error 0.19540825010672513\n",
      "Variance Error 0.006238078198674747\n",
      "n_estimator: 40\n",
      "Bias Error 0.19069849994818622\n",
      "Variance Error 0.004631537614899288\n",
      "n_estimator: 60\n",
      "Bias Error 0.1886983392199646\n",
      "Variance Error 0.003980810746554363\n",
      "n_estimator: 80\n",
      "Bias Error 0.1883090221820083\n",
      "Variance Error 0.004616904892296803\n",
      "n_estimator: 100\n",
      "Bias Error 0.18745376862741148\n",
      "Variance Error 0.004967844521680093\n",
      "n_estimator: 120\n",
      "Bias Error 0.1876877171322271\n",
      "Variance Error 0.004946021686830334\n",
      "n_estimator: 150\n",
      "Bias Error 0.1877866496479882\n",
      "Variance Error 0.005057665107292359\n",
      "n_estimator: 200\n",
      "Bias Error 0.18792424953001297\n",
      "Variance Error 0.005223477047089322\n",
      "n_estimator: 250\n",
      "Bias Error 0.18755010706185948\n",
      "Variance Error 0.005932183704945998\n",
      "n_estimator: 300\n",
      "Bias Error 0.1874493634115314\n",
      "Variance Error 0.005661315327148637\n",
      "n_estimator: 400\n",
      "Bias Error 0.1870770958671667\n",
      "Variance Error 0.006432106650580119\n"
     ]
    }
   ],
   "source": [
    "# Parameter Tuning\n",
    "be=[]\n",
    "ve=[]\n",
    "for i in [5,10,20,40,60,80,100,120,150,200,250,300,400]:\n",
    "    #for j in [10,15,20,30]:\n",
    "    dt=RandomForestClassifier(n_estimators=i,random_state=48)\n",
    "    #scorer = make_scorer(f1_score, average = 'weighted')\n",
    "    score=cross_val_score(dt,inp_bal,out_bal,cv=kf,scoring='f1')\n",
    "    print('n_estimator:',i)\n",
    "    print('Bias Error',1-np.mean(score))\n",
    "    print('Variance Error',np.std(score)/np.mean(score))\n",
    "    be.append(1-np.mean(score))\n",
    "    ve.append(np.std(score)/np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c38a718708>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot([5,10,20,40,60,80,100,120,150,200,250,300,400],be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c38a56bfc8>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([5,10,20,40,60,80,100,120,150,200,250,300,400],ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "be1=pd.DataFrame(be)/pd.DataFrame(be).sum()\n",
    "ve1=pd.DataFrame(ve)/pd.DataFrame(ve).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c38b0d7d88>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([5,10,20,40,60,80,100,120,150,200,250,300,400],be1)\n",
    "plt.plot([5,10,20,40,60,80,100,120,150,200,250,300,400],ve1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'n_estimators':[20,40,60,80,100,120,140,160],\n",
    "        #'max_features':['auto','sqrt','log2'],\n",
    "        #'criterion':['gini','entropy'],\n",
    "        'max_depth':[10,15,20,25,30,40]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mod1=RandomForestClassifier()\n",
    "hyp_mod=GridSearchCV(rf_mod1,param_grid=params,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_mod=hyp_mod.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 100}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tun_mod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8171460646397776"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tun_mod.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 15)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=pd.DataFrame(tun_mod.cv_results_)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227407</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.018388</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.786684</td>\n",
       "      <td>0.796248</td>\n",
       "      <td>0.787576</td>\n",
       "      <td>0.798855</td>\n",
       "      <td>0.795902</td>\n",
       "      <td>0.793053</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.458723</td>\n",
       "      <td>0.018214</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 40}</td>\n",
       "      <td>0.785543</td>\n",
       "      <td>0.794499</td>\n",
       "      <td>0.791981</td>\n",
       "      <td>0.800930</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.794591</td>\n",
       "      <td>0.005623</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.632625</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 60}</td>\n",
       "      <td>0.784664</td>\n",
       "      <td>0.793220</td>\n",
       "      <td>0.789446</td>\n",
       "      <td>0.800104</td>\n",
       "      <td>0.797162</td>\n",
       "      <td>0.792919</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.842669</td>\n",
       "      <td>0.021775</td>\n",
       "      <td>0.060698</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 80}</td>\n",
       "      <td>0.786038</td>\n",
       "      <td>0.795131</td>\n",
       "      <td>0.790916</td>\n",
       "      <td>0.803952</td>\n",
       "      <td>0.798837</td>\n",
       "      <td>0.794975</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.051601</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.074176</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.786981</td>\n",
       "      <td>0.793933</td>\n",
       "      <td>0.790175</td>\n",
       "      <td>0.800519</td>\n",
       "      <td>0.796199</td>\n",
       "      <td>0.793561</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.273510</td>\n",
       "      <td>0.046924</td>\n",
       "      <td>0.091933</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 120}</td>\n",
       "      <td>0.783511</td>\n",
       "      <td>0.790407</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>0.799684</td>\n",
       "      <td>0.792357</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.446185</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.100919</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>10</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 140}</td>\n",
       "      <td>0.784958</td>\n",
       "      <td>0.796451</td>\n",
       "      <td>0.789570</td>\n",
       "      <td>0.800625</td>\n",
       "      <td>0.800842</td>\n",
       "      <td>0.794489</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.700092</td>\n",
       "      <td>0.052019</td>\n",
       "      <td>0.113315</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>10</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 160}</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>0.796863</td>\n",
       "      <td>0.792374</td>\n",
       "      <td>0.800832</td>\n",
       "      <td>0.800105</td>\n",
       "      <td>0.795306</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.284467</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.023866</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 20}</td>\n",
       "      <td>0.803590</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>0.805242</td>\n",
       "      <td>0.808102</td>\n",
       "      <td>0.813935</td>\n",
       "      <td>0.807496</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.551234</td>\n",
       "      <td>0.035777</td>\n",
       "      <td>0.041776</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 40}</td>\n",
       "      <td>0.800846</td>\n",
       "      <td>0.807210</td>\n",
       "      <td>0.805650</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.811458</td>\n",
       "      <td>0.807552</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.789473</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.057012</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 60}</td>\n",
       "      <td>0.803383</td>\n",
       "      <td>0.813357</td>\n",
       "      <td>0.810107</td>\n",
       "      <td>0.812127</td>\n",
       "      <td>0.812026</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.057880</td>\n",
       "      <td>0.017414</td>\n",
       "      <td>0.081947</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 80}</td>\n",
       "      <td>0.803901</td>\n",
       "      <td>0.809660</td>\n",
       "      <td>0.807622</td>\n",
       "      <td>0.812015</td>\n",
       "      <td>0.813330</td>\n",
       "      <td>0.809305</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.337882</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.101643</td>\n",
       "      <td>0.020303</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.799788</td>\n",
       "      <td>0.808797</td>\n",
       "      <td>0.811685</td>\n",
       "      <td>0.813568</td>\n",
       "      <td>0.812435</td>\n",
       "      <td>0.809255</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.566943</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.113550</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 120}</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.806024</td>\n",
       "      <td>0.811443</td>\n",
       "      <td>0.812257</td>\n",
       "      <td>0.816008</td>\n",
       "      <td>0.809673</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.843096</td>\n",
       "      <td>0.028739</td>\n",
       "      <td>0.129523</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 140}</td>\n",
       "      <td>0.801795</td>\n",
       "      <td>0.809832</td>\n",
       "      <td>0.806477</td>\n",
       "      <td>0.814278</td>\n",
       "      <td>0.812288</td>\n",
       "      <td>0.808934</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.092080</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>0.148636</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>15</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 160}</td>\n",
       "      <td>0.799365</td>\n",
       "      <td>0.807573</td>\n",
       "      <td>0.807812</td>\n",
       "      <td>0.813893</td>\n",
       "      <td>0.813851</td>\n",
       "      <td>0.808499</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.306986</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>0.026739</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 20}</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.808700</td>\n",
       "      <td>0.814510</td>\n",
       "      <td>0.812015</td>\n",
       "      <td>0.809666</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.604827</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.049240</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 40}</td>\n",
       "      <td>0.806214</td>\n",
       "      <td>0.808577</td>\n",
       "      <td>0.811850</td>\n",
       "      <td>0.819077</td>\n",
       "      <td>0.815817</td>\n",
       "      <td>0.812307</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.915081</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 60}</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.810041</td>\n",
       "      <td>0.814371</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.820818</td>\n",
       "      <td>0.814694</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.290629</td>\n",
       "      <td>0.025739</td>\n",
       "      <td>0.089642</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 80}</td>\n",
       "      <td>0.810313</td>\n",
       "      <td>0.808258</td>\n",
       "      <td>0.813055</td>\n",
       "      <td>0.820961</td>\n",
       "      <td>0.816104</td>\n",
       "      <td>0.813738</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.543500</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.124778</td>\n",
       "      <td>0.023785</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>0.812893</td>\n",
       "      <td>0.812178</td>\n",
       "      <td>0.819383</td>\n",
       "      <td>0.822526</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.817146</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.820179</td>\n",
       "      <td>0.017985</td>\n",
       "      <td>0.131292</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 120}</td>\n",
       "      <td>0.811564</td>\n",
       "      <td>0.813498</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>0.818276</td>\n",
       "      <td>0.815546</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.148001</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.152544</td>\n",
       "      <td>0.007402</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 140}</td>\n",
       "      <td>0.813435</td>\n",
       "      <td>0.811062</td>\n",
       "      <td>0.813365</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.817803</td>\n",
       "      <td>0.815183</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.487776</td>\n",
       "      <td>0.086511</td>\n",
       "      <td>0.172640</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 160}</td>\n",
       "      <td>0.809060</td>\n",
       "      <td>0.812274</td>\n",
       "      <td>0.815741</td>\n",
       "      <td>0.818865</td>\n",
       "      <td>0.817333</td>\n",
       "      <td>0.814655</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.337667</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>0.027902</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 20}</td>\n",
       "      <td>0.802628</td>\n",
       "      <td>0.797914</td>\n",
       "      <td>0.804269</td>\n",
       "      <td>0.808335</td>\n",
       "      <td>0.806367</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.673157</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.051798</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 40}</td>\n",
       "      <td>0.799158</td>\n",
       "      <td>0.805808</td>\n",
       "      <td>0.811345</td>\n",
       "      <td>0.809943</td>\n",
       "      <td>0.810246</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000962</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>25</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 60}</td>\n",
       "      <td>0.803906</td>\n",
       "      <td>0.806318</td>\n",
       "      <td>0.810557</td>\n",
       "      <td>0.808919</td>\n",
       "      <td>0.811291</td>\n",
       "      <td>0.808198</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.317319</td>\n",
       "      <td>0.018884</td>\n",
       "      <td>0.097185</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>25</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 80}</td>\n",
       "      <td>0.802739</td>\n",
       "      <td>0.803326</td>\n",
       "      <td>0.813542</td>\n",
       "      <td>0.809610</td>\n",
       "      <td>0.811232</td>\n",
       "      <td>0.808090</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.718381</td>\n",
       "      <td>0.067098</td>\n",
       "      <td>0.129332</td>\n",
       "      <td>0.028455</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 100}</td>\n",
       "      <td>0.803999</td>\n",
       "      <td>0.805729</td>\n",
       "      <td>0.804700</td>\n",
       "      <td>0.814452</td>\n",
       "      <td>0.809387</td>\n",
       "      <td>0.807653</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.989672</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>0.139052</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 120}</td>\n",
       "      <td>0.805167</td>\n",
       "      <td>0.808599</td>\n",
       "      <td>0.809152</td>\n",
       "      <td>0.811257</td>\n",
       "      <td>0.809474</td>\n",
       "      <td>0.808730</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.327516</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.165834</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>25</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 140}</td>\n",
       "      <td>0.804859</td>\n",
       "      <td>0.801978</td>\n",
       "      <td>0.808466</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.809698</td>\n",
       "      <td>0.807810</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.648371</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>25</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 25, 'n_estimators': 160}</td>\n",
       "      <td>0.801474</td>\n",
       "      <td>0.803952</td>\n",
       "      <td>0.808466</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>0.809474</td>\n",
       "      <td>0.806632</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.345781</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.029666</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 20}</td>\n",
       "      <td>0.790587</td>\n",
       "      <td>0.797694</td>\n",
       "      <td>0.796521</td>\n",
       "      <td>0.797806</td>\n",
       "      <td>0.806511</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.685730</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 40}</td>\n",
       "      <td>0.795784</td>\n",
       "      <td>0.794218</td>\n",
       "      <td>0.804827</td>\n",
       "      <td>0.807981</td>\n",
       "      <td>0.802304</td>\n",
       "      <td>0.801023</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.026619</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.076739</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 60}</td>\n",
       "      <td>0.798633</td>\n",
       "      <td>0.797597</td>\n",
       "      <td>0.804999</td>\n",
       "      <td>0.802075</td>\n",
       "      <td>0.805425</td>\n",
       "      <td>0.801746</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.376366</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>0.105254</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 80}</td>\n",
       "      <td>0.800211</td>\n",
       "      <td>0.798225</td>\n",
       "      <td>0.812288</td>\n",
       "      <td>0.807961</td>\n",
       "      <td>0.808466</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.774384</td>\n",
       "      <td>0.057165</td>\n",
       "      <td>0.141117</td>\n",
       "      <td>0.018049</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>0.798736</td>\n",
       "      <td>0.796668</td>\n",
       "      <td>0.806173</td>\n",
       "      <td>0.806535</td>\n",
       "      <td>0.809598</td>\n",
       "      <td>0.803542</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.142035</td>\n",
       "      <td>0.212794</td>\n",
       "      <td>0.148366</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 120}</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>0.811065</td>\n",
       "      <td>0.809389</td>\n",
       "      <td>0.808555</td>\n",
       "      <td>0.806388</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.384818</td>\n",
       "      <td>0.014581</td>\n",
       "      <td>0.166528</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>30</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 140}</td>\n",
       "      <td>0.804097</td>\n",
       "      <td>0.797185</td>\n",
       "      <td>0.810219</td>\n",
       "      <td>0.806210</td>\n",
       "      <td>0.807592</td>\n",
       "      <td>0.805060</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.718930</td>\n",
       "      <td>0.055886</td>\n",
       "      <td>0.194236</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>30</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 160}</td>\n",
       "      <td>0.801996</td>\n",
       "      <td>0.801457</td>\n",
       "      <td>0.808965</td>\n",
       "      <td>0.807245</td>\n",
       "      <td>0.809276</td>\n",
       "      <td>0.805788</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.349012</td>\n",
       "      <td>0.016187</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 20}</td>\n",
       "      <td>0.790391</td>\n",
       "      <td>0.795988</td>\n",
       "      <td>0.794838</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>0.799473</td>\n",
       "      <td>0.796722</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.688932</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.052916</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 40}</td>\n",
       "      <td>0.798732</td>\n",
       "      <td>0.801465</td>\n",
       "      <td>0.809710</td>\n",
       "      <td>0.806862</td>\n",
       "      <td>0.807933</td>\n",
       "      <td>0.804941</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.275554</td>\n",
       "      <td>0.188077</td>\n",
       "      <td>0.093866</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 60}</td>\n",
       "      <td>0.799684</td>\n",
       "      <td>0.798225</td>\n",
       "      <td>0.804081</td>\n",
       "      <td>0.803507</td>\n",
       "      <td>0.806587</td>\n",
       "      <td>0.802417</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.368212</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.098002</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 80}</td>\n",
       "      <td>0.797262</td>\n",
       "      <td>0.796646</td>\n",
       "      <td>0.805331</td>\n",
       "      <td>0.808675</td>\n",
       "      <td>0.801882</td>\n",
       "      <td>0.801959</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.789958</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>0.126605</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 100}</td>\n",
       "      <td>0.797052</td>\n",
       "      <td>0.800104</td>\n",
       "      <td>0.810839</td>\n",
       "      <td>0.807154</td>\n",
       "      <td>0.810034</td>\n",
       "      <td>0.805037</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2.132144</td>\n",
       "      <td>0.080121</td>\n",
       "      <td>0.141828</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 120}</td>\n",
       "      <td>0.800316</td>\n",
       "      <td>0.800624</td>\n",
       "      <td>0.810146</td>\n",
       "      <td>0.805584</td>\n",
       "      <td>0.805846</td>\n",
       "      <td>0.804503</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.414436</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>0.170128</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 140}</td>\n",
       "      <td>0.801579</td>\n",
       "      <td>0.800731</td>\n",
       "      <td>0.808666</td>\n",
       "      <td>0.806909</td>\n",
       "      <td>0.808444</td>\n",
       "      <td>0.805266</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.748731</td>\n",
       "      <td>0.027242</td>\n",
       "      <td>0.191324</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>{'max_depth': 40, 'n_estimators': 160}</td>\n",
       "      <td>0.797998</td>\n",
       "      <td>0.797086</td>\n",
       "      <td>0.807072</td>\n",
       "      <td>0.806009</td>\n",
       "      <td>0.806048</td>\n",
       "      <td>0.802843</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.227407      0.019231         0.018388        0.004327   \n",
       "1        0.458723      0.018214         0.035135        0.001523   \n",
       "2        0.632625      0.006444         0.051478        0.003396   \n",
       "3        0.842669      0.021775         0.060698        0.001703   \n",
       "4        1.051601      0.016299         0.074176        0.005177   \n",
       "5        1.273510      0.046924         0.091933        0.009932   \n",
       "6        1.446185      0.004035         0.100919        0.003451   \n",
       "7        1.700092      0.052019         0.113315        0.004626   \n",
       "8        0.284467      0.030687         0.023866        0.004616   \n",
       "9        0.551234      0.035777         0.041776        0.003470   \n",
       "10       0.789473      0.012342         0.057012        0.004076   \n",
       "11       1.057880      0.017414         0.081947        0.014660   \n",
       "12       1.337882      0.032898         0.101643        0.020303   \n",
       "13       1.566943      0.010932         0.113550        0.007879   \n",
       "14       1.843096      0.028739         0.129523        0.004186   \n",
       "15       2.092080      0.011823         0.148636        0.006509   \n",
       "16       0.306986      0.010450         0.026739        0.005149   \n",
       "17       0.604827      0.012017         0.049240        0.004858   \n",
       "18       0.915081      0.010102         0.070864        0.005698   \n",
       "19       1.290629      0.025739         0.089642        0.000932   \n",
       "20       1.543500      0.026348         0.124778        0.023785   \n",
       "21       1.820179      0.017985         0.131292        0.005813   \n",
       "22       2.148001      0.026793         0.152544        0.007402   \n",
       "23       2.487776      0.086511         0.172640        0.003319   \n",
       "24       0.337667      0.009396         0.027902        0.001436   \n",
       "25       0.673157      0.015875         0.051798        0.001880   \n",
       "26       1.000962      0.004683         0.076707        0.003093   \n",
       "27       1.317319      0.018884         0.097185        0.007965   \n",
       "28       1.718381      0.067098         0.129332        0.028455   \n",
       "29       1.989672      0.017864         0.139052        0.002494   \n",
       "30       2.327516      0.012916         0.165834        0.009508   \n",
       "31       2.648371      0.019628         0.185843        0.007558   \n",
       "32       0.345781      0.009838         0.029666        0.000563   \n",
       "33       0.685730      0.014110         0.054425        0.003938   \n",
       "34       1.026619      0.020301         0.076739        0.004337   \n",
       "35       1.376366      0.026576         0.105254        0.005373   \n",
       "36       1.774384      0.057165         0.141117        0.018049   \n",
       "37       2.142035      0.212794         0.148366        0.005123   \n",
       "38       2.384818      0.014581         0.166528        0.004802   \n",
       "39       2.718930      0.055886         0.194236        0.005665   \n",
       "40       0.349012      0.016187         0.028587        0.003331   \n",
       "41       0.688932      0.007362         0.052916        0.003538   \n",
       "42       1.275554      0.188077         0.093866        0.021764   \n",
       "43       1.368212      0.014388         0.098002        0.006946   \n",
       "44       1.789958      0.034065         0.126605        0.004837   \n",
       "45       2.132144      0.080121         0.141828        0.006185   \n",
       "46       2.414436      0.032746         0.170128        0.008513   \n",
       "47       2.748731      0.027242         0.191324        0.003357   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "0               10                 20   {'max_depth': 10, 'n_estimators': 20}   \n",
       "1               10                 40   {'max_depth': 10, 'n_estimators': 40}   \n",
       "2               10                 60   {'max_depth': 10, 'n_estimators': 60}   \n",
       "3               10                 80   {'max_depth': 10, 'n_estimators': 80}   \n",
       "4               10                100  {'max_depth': 10, 'n_estimators': 100}   \n",
       "5               10                120  {'max_depth': 10, 'n_estimators': 120}   \n",
       "6               10                140  {'max_depth': 10, 'n_estimators': 140}   \n",
       "7               10                160  {'max_depth': 10, 'n_estimators': 160}   \n",
       "8               15                 20   {'max_depth': 15, 'n_estimators': 20}   \n",
       "9               15                 40   {'max_depth': 15, 'n_estimators': 40}   \n",
       "10              15                 60   {'max_depth': 15, 'n_estimators': 60}   \n",
       "11              15                 80   {'max_depth': 15, 'n_estimators': 80}   \n",
       "12              15                100  {'max_depth': 15, 'n_estimators': 100}   \n",
       "13              15                120  {'max_depth': 15, 'n_estimators': 120}   \n",
       "14              15                140  {'max_depth': 15, 'n_estimators': 140}   \n",
       "15              15                160  {'max_depth': 15, 'n_estimators': 160}   \n",
       "16              20                 20   {'max_depth': 20, 'n_estimators': 20}   \n",
       "17              20                 40   {'max_depth': 20, 'n_estimators': 40}   \n",
       "18              20                 60   {'max_depth': 20, 'n_estimators': 60}   \n",
       "19              20                 80   {'max_depth': 20, 'n_estimators': 80}   \n",
       "20              20                100  {'max_depth': 20, 'n_estimators': 100}   \n",
       "21              20                120  {'max_depth': 20, 'n_estimators': 120}   \n",
       "22              20                140  {'max_depth': 20, 'n_estimators': 140}   \n",
       "23              20                160  {'max_depth': 20, 'n_estimators': 160}   \n",
       "24              25                 20   {'max_depth': 25, 'n_estimators': 20}   \n",
       "25              25                 40   {'max_depth': 25, 'n_estimators': 40}   \n",
       "26              25                 60   {'max_depth': 25, 'n_estimators': 60}   \n",
       "27              25                 80   {'max_depth': 25, 'n_estimators': 80}   \n",
       "28              25                100  {'max_depth': 25, 'n_estimators': 100}   \n",
       "29              25                120  {'max_depth': 25, 'n_estimators': 120}   \n",
       "30              25                140  {'max_depth': 25, 'n_estimators': 140}   \n",
       "31              25                160  {'max_depth': 25, 'n_estimators': 160}   \n",
       "32              30                 20   {'max_depth': 30, 'n_estimators': 20}   \n",
       "33              30                 40   {'max_depth': 30, 'n_estimators': 40}   \n",
       "34              30                 60   {'max_depth': 30, 'n_estimators': 60}   \n",
       "35              30                 80   {'max_depth': 30, 'n_estimators': 80}   \n",
       "36              30                100  {'max_depth': 30, 'n_estimators': 100}   \n",
       "37              30                120  {'max_depth': 30, 'n_estimators': 120}   \n",
       "38              30                140  {'max_depth': 30, 'n_estimators': 140}   \n",
       "39              30                160  {'max_depth': 30, 'n_estimators': 160}   \n",
       "40              40                 20   {'max_depth': 40, 'n_estimators': 20}   \n",
       "41              40                 40   {'max_depth': 40, 'n_estimators': 40}   \n",
       "42              40                 60   {'max_depth': 40, 'n_estimators': 60}   \n",
       "43              40                 80   {'max_depth': 40, 'n_estimators': 80}   \n",
       "44              40                100  {'max_depth': 40, 'n_estimators': 100}   \n",
       "45              40                120  {'max_depth': 40, 'n_estimators': 120}   \n",
       "46              40                140  {'max_depth': 40, 'n_estimators': 140}   \n",
       "47              40                160  {'max_depth': 40, 'n_estimators': 160}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.786684           0.796248           0.787576   \n",
       "1            0.785543           0.794499           0.791981   \n",
       "2            0.784664           0.793220           0.789446   \n",
       "3            0.786038           0.795131           0.790916   \n",
       "4            0.786981           0.793933           0.790175   \n",
       "5            0.783511           0.790407           0.786517   \n",
       "6            0.784958           0.796451           0.789570   \n",
       "7            0.786356           0.796863           0.792374   \n",
       "8            0.803590           0.806610           0.805242   \n",
       "9            0.800846           0.807210           0.805650   \n",
       "10           0.803383           0.813357           0.810107   \n",
       "11           0.803901           0.809660           0.807622   \n",
       "12           0.799788           0.808797           0.811685   \n",
       "13           0.802632           0.806024           0.811443   \n",
       "14           0.801795           0.809832           0.806477   \n",
       "15           0.799365           0.807573           0.807812   \n",
       "16           0.808789           0.804314           0.808700   \n",
       "17           0.806214           0.808577           0.811850   \n",
       "18           0.809636           0.810041           0.814371   \n",
       "19           0.810313           0.808258           0.813055   \n",
       "20           0.812893           0.812178           0.819383   \n",
       "21           0.811564           0.813498           0.813559   \n",
       "22           0.813435           0.811062           0.813365   \n",
       "23           0.809060           0.812274           0.815741   \n",
       "24           0.802628           0.797914           0.804269   \n",
       "25           0.799158           0.805808           0.811345   \n",
       "26           0.803906           0.806318           0.810557   \n",
       "27           0.802739           0.803326           0.813542   \n",
       "28           0.803999           0.805729           0.804700   \n",
       "29           0.805167           0.808599           0.809152   \n",
       "30           0.804859           0.801978           0.808466   \n",
       "31           0.801474           0.803952           0.808466   \n",
       "32           0.790587           0.797694           0.796521   \n",
       "33           0.795784           0.794218           0.804827   \n",
       "34           0.798633           0.797597           0.804999   \n",
       "35           0.800211           0.798225           0.812288   \n",
       "36           0.798736           0.796668           0.806173   \n",
       "37           0.801265           0.801666           0.811065   \n",
       "38           0.804097           0.797185           0.810219   \n",
       "39           0.801996           0.801457           0.808965   \n",
       "40           0.790391           0.795988           0.794838   \n",
       "41           0.798732           0.801465           0.809710   \n",
       "42           0.799684           0.798225           0.804081   \n",
       "43           0.797262           0.796646           0.805331   \n",
       "44           0.797052           0.800104           0.810839   \n",
       "45           0.800316           0.800624           0.810146   \n",
       "46           0.801579           0.800731           0.808666   \n",
       "47           0.797998           0.797086           0.807072   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.798855           0.795902         0.793053        0.004951   \n",
       "1            0.800930           0.800000         0.794591        0.005623   \n",
       "2            0.800104           0.797162         0.792919        0.005476   \n",
       "3            0.803952           0.798837         0.794975        0.006195   \n",
       "4            0.800519           0.796199         0.793561        0.004696   \n",
       "5            0.801666           0.799684         0.792357        0.007162   \n",
       "6            0.800625           0.800842         0.794489        0.006275   \n",
       "7            0.800832           0.800105         0.795306        0.005379   \n",
       "8            0.808102           0.813935         0.807496        0.003548   \n",
       "9            0.812598           0.811458         0.807552        0.004229   \n",
       "10           0.812127           0.812026         0.810200        0.003564   \n",
       "11           0.812015           0.813330         0.809305        0.003338   \n",
       "12           0.813568           0.812435         0.809255        0.004989   \n",
       "13           0.812257           0.816008         0.809673        0.004751   \n",
       "14           0.814278           0.812288         0.808934        0.004419   \n",
       "15           0.813893           0.813851         0.808499        0.005339   \n",
       "16           0.814510           0.812015         0.809666        0.003444   \n",
       "17           0.819077           0.815817         0.812307        0.004678   \n",
       "18           0.818605           0.820818         0.814694        0.004475   \n",
       "19           0.820961           0.816104         0.813738        0.004472   \n",
       "20           0.822526           0.818750         0.817146        0.003982   \n",
       "21           0.820830           0.818276         0.815546        0.003446   \n",
       "22           0.820248           0.817803         0.815183        0.003343   \n",
       "23           0.818865           0.817333         0.814655        0.003551   \n",
       "24           0.808335           0.806367         0.803903        0.003559   \n",
       "25           0.809943           0.810246         0.807300        0.004484   \n",
       "26           0.808919           0.811291         0.808198        0.002742   \n",
       "27           0.809610           0.811232         0.808090        0.004318   \n",
       "28           0.814452           0.809387         0.807653        0.003873   \n",
       "29           0.811257           0.809474         0.808730        0.001991   \n",
       "30           0.814050           0.809698         0.807810        0.004139   \n",
       "31           0.809794           0.809474         0.806632        0.003323   \n",
       "32           0.797806           0.806511         0.797824        0.005090   \n",
       "33           0.807981           0.802304         0.801023        0.005259   \n",
       "34           0.802075           0.805425         0.801746        0.003198   \n",
       "35           0.807961           0.808466         0.805430        0.005326   \n",
       "36           0.806535           0.809598         0.803542        0.004958   \n",
       "37           0.809389           0.808555         0.806388        0.004102   \n",
       "38           0.806210           0.807592         0.805060        0.004411   \n",
       "39           0.807245           0.809276         0.805788        0.003392   \n",
       "40           0.802920           0.799473         0.796722        0.004246   \n",
       "41           0.806862           0.807933         0.804941        0.004148   \n",
       "42           0.803507           0.806587         0.802417        0.003046   \n",
       "43           0.808675           0.801882         0.801959        0.004621   \n",
       "44           0.807154           0.810034         0.805037        0.005499   \n",
       "45           0.805584           0.805846         0.804503        0.003672   \n",
       "46           0.806909           0.808444         0.805266        0.003421   \n",
       "47           0.806009           0.806048         0.802843        0.004354   \n",
       "\n",
       "    rank_test_score  \n",
       "0                46  \n",
       "1                43  \n",
       "2                47  \n",
       "3                42  \n",
       "4                45  \n",
       "5                48  \n",
       "6                44  \n",
       "7                41  \n",
       "8                21  \n",
       "9                20  \n",
       "10                8  \n",
       "11               11  \n",
       "12               12  \n",
       "13                9  \n",
       "14               13  \n",
       "15               15  \n",
       "16               10  \n",
       "17                7  \n",
       "18                4  \n",
       "19                6  \n",
       "20                1  \n",
       "21                2  \n",
       "22                3  \n",
       "23                5  \n",
       "24               32  \n",
       "25               22  \n",
       "26               16  \n",
       "27               17  \n",
       "28               19  \n",
       "29               14  \n",
       "30               18  \n",
       "31               23  \n",
       "32               39  \n",
       "33               38  \n",
       "34               37  \n",
       "35               26  \n",
       "36               33  \n",
       "37               24  \n",
       "38               28  \n",
       "39               25  \n",
       "40               40  \n",
       "41               30  \n",
       "42               35  \n",
       "43               36  \n",
       "44               29  \n",
       "45               31  \n",
       "46               27  \n",
       "47               34  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mod=RandomForestClassifier(**tun_mod.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mod.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1=final_mod.predict(xtest)\n",
    "ypred1_train=final_mod.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.88      6016\n",
      "         1.0       0.85      0.80      0.82      4184\n",
      "\n",
      "    accuracy                           0.86     10200\n",
      "   macro avg       0.86      0.85      0.85     10200\n",
      "weighted avg       0.86      0.86      0.86     10200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred1))\n",
    "#Has imporved further now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8233392206371681 0.007118398771231839\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(final_mod, inp_bal, out_bal, cv=kf, scoring='f1')\n",
    "print(np.mean(score),np.std(score)/np.mean(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
